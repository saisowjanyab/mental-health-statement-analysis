{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.models import Sequential \nfrom keras.layers import Embedding,LSTM,Dense,GRU\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stmts = pd.read_csv(\"../input/zindi-aldc/Train_df.csv\")\n\nstmts.isnull().values.any()\n\n\nstmts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stmts.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.countplot(x='label', data=stmts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef preprocess(sen):\n   \n    # Remove punctuations and numbers\n    sen = re.sub('[^a-zA-Z]', ' ', sen)\n\n    # Single character removal\n    sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)\n\n    # Removing multiple spaces\n    sen = re.sub(r'\\s+', ' ', sen)\n    \n    sen=sen.lower()\n\n    return sen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nencoding_dict={'Depression':0,'Drugs':1,'Suicide':2,'Alcohol':3}\ny =stmts['label']\ny = np.array(list(map(lambda x: encoding_dict[x], y)))\ny[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_df = stmts.drop(['label'],axis=1)\nX_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\nfor stmt in list(X_df['text']):\n    X.append(preprocess(stmt))\nX[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\ny_one_hot=to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.20, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[2]\n# X_test[:10]\n# X_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(X_train)\n\nX_train_token = tokenizer.texts_to_sequences(X_train)\nX_test_token = tokenizer.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_token[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(vocab_size)\nmaxlen = 10\n\nX_train_pad = pad_sequences(X_train_token, padding='post', maxlen=maxlen)\nX_test_pad = pad_sequences(X_test_token, padding='post', maxlen=maxlen)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.metrics import categorical_crossentropy\nfrom keras.layers import Dropout, Dense, Flatten, BatchNormalization\nfrom keras.optimizers import SGD, Adam\nfrom keras.models import Model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hid1=5\nhid2=25\nhid3=125\nembed=200\nout= 4 \nepoch=100\nearly=15\n# sgd=SGD(lr=0.01)\n\n\ndef model():\n    model=Sequential()\n    model.add(Embedding(vocab_size, embed, input_length=maxlen))\n    model.add(Flatten())\n    model.add(Dense(hid2,activation =\"sigmoid\"))\n#     model.add(Dropout(0.4))\n    model.add(Dense(hid3,activation =\"sigmoid\"))\n    model.add(Dense(out,activation =\"softmax\"))\n    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.005) , metrics=['accuracy'])\n    return model\n\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es_callback = EarlyStopping(monitor=\"val_loss\", patience=20)\ncallbacks = [es_callback]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train_pad,\n              y_train,\n              epochs=100,\n              batch_size=31,\n              validation_data=(X_test_pad, y_test),\n                                \n             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"adam005acc7661.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inferdata=pd.read_csv('../input/zindi-aldc/Test_df.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inferdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"infer=[]\nfor stmt in list(inferdata['text']):\n    infer.append(preprocess(stmt))\ninfertoken = tokenizer.texts_to_sequences(infer)\ninferpad = pad_sequences(infertoken, padding='post', maxlen=15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pad[:4]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inferpad[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inferdata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score=model.evaluate(X_test_pad, y_test)\nprint(test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_index=model.predict(inferpad,batch_size=30)\npredind = np.argmax(pred_index, axis=1)\npredind[:10]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}